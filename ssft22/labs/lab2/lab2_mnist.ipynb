{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In lab2, we will guide you through the basic Scallop Python API, called scallopy.\n",
    "In this tutorial, you will learn:\n",
    "1. How to construct and execute a Scallop program in Python using Scallopy.\n",
    "2. How to perform a learning task in Python through Scallopy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hello Scallopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write our first hello world Python program. You can do this purely through the scallopy interface. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start from constructing a scallopy context\n",
    "import scallopy\n",
    "ctx = scallopy.ScallopContext()\n",
    "\n",
    "# We declare a relation type using 'add_relation'. \n",
    "# This is equvalent to 'type hello(String)' in a .scl file\n",
    "ctx.add_relation(\"hello\", str)\n",
    "\n",
    "# We add the fact hello(\"Hello World\") to the scallopy context \n",
    "ctx.add_facts(\"hello\", [(\"Hello World\",)])\n",
    "\n",
    "# We can execute the context through 'run'\n",
    "ctx.run()\n",
    "print(list(ctx.relation(\"hello\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## MNIST\n",
    "<div>\n",
    "  <img src=\"img/mnist_example.png\" width=\"300\"/>\n",
    "</div>\n",
    "\n",
    "### P1: Count 2\n",
    "Let's first construct the symbolic representation of the MNIST image, where the input facts for `digit(i, d)` where i is the image id, and d is the numerical value of the corresponding image.\n",
    "Write a rule that counts how many `2` are there in the image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scallopy\n",
    "\n",
    "ctx = scallopy.ScallopContext()\n",
    "\n",
    "# TODO: Write the discrete input facts and rule here\n",
    "\n",
    "ctx.run()\n",
    "print(list(ctx.relation(\"num_of_2\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P2: Probabilistic Less than 5\n",
    "Let's try to write a probabilistic symbolic representation of the MNIST images, where the input facts for `digit(i, d)` where i is the image id, and d is the numerical value of the corresponding image. \n",
    "The probabilities for the input facts should be randomly generated, ranging from 0 to 1. \n",
    "Further, the probabilities of one image being recognized to all different numbers (0-9) shall sum to 1.\n",
    "Write a rule that counts how many numbers are less than 5 in the image. \n",
    "Use \"minmaxprob\" semiring to compute the query result with probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P3: MNIST Sum 3\n",
    "In this practice, we will use scallopy to train an MNIST digit recognition network. Given three MNIST numbers and their sum, we want to train a classifier that can identify the digits, and yields a correct sum of the input images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1** Dataloader construction. \n",
    "\n",
    "First, we want to construct a train data loader, and a test data loader separately. \n",
    "Please fill in the `get_item` and `collate_fn` functions for the dataloader.\n",
    "The `get_item` function shall take in an index and return a tuple. The first tuple element is a triplet of tensorized images, and the second tuple element is the sum of the images.\n",
    "The `collate_fn` function shall take in a list of tuples returned by `get_item`, and return a tuple. The first tuple element is a triplet of batched tensors representing the images, and the second element is a tensor of batched sum values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from typing import *\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "mnist_img_transform = torchvision.transforms.Compose([\n",
    "  torchvision.transforms.ToTensor(),\n",
    "  torchvision.transforms.Normalize(\n",
    "    (0.1307,), (0.3081,)\n",
    "  )\n",
    "])\n",
    "\n",
    "class MNISTSum3Dataset(torch.utils.data.Dataset):\n",
    "  def __init__(\n",
    "    self,\n",
    "    root: str,\n",
    "    train: bool = True,\n",
    "    transform: Optional[Callable] = None,\n",
    "    target_transform: Optional[Callable] = None,\n",
    "    download: bool = False,\n",
    "  ):\n",
    "    # Contains a MNIST dataset\n",
    "    self.mnist_dataset = torchvision.datasets.MNIST(\n",
    "      root,\n",
    "      train=train,\n",
    "      transform=transform,\n",
    "      target_transform=target_transform,\n",
    "      download=download,\n",
    "    )\n",
    "    self.index_map = list(range(len(self.mnist_dataset)))\n",
    "    random.shuffle(self.index_map)\n",
    "\n",
    "  def __len__(self):\n",
    "    return int(len(self.mnist_dataset) / 3)\n",
    "\n",
    "  # The `get_item` function shall take in an index and return a tuple. \n",
    "  # The first tuple element is a triplet of tensorized images, \n",
    "  # and the second tuple element is the sum of the images.\n",
    "  def __getitem__(self, idx):\n",
    "    # TODO: Complete the __getitem__ method\n",
    "    raise NotImplementedError\n",
    "\n",
    "  # The `collate_fn` function shall take in a list of tuples returned by `get_item`, \n",
    "  # and return a tuple. The first tuple element is triplet of batched tensors \n",
    "  # representing the images, and the second element is a tensor of batched sum values.  \n",
    "  @staticmethod\n",
    "  def collate_fn(batch):\n",
    "    # TODO: complete the collate_fn method\n",
    "    raise NotImplementedError\n",
    "\n",
    "def mnist_sum_3_loader(data_dir, batch_size_train, batch_size_test):\n",
    "\n",
    "  train_loader = torch.utils.data.DataLoader(\n",
    "    MNISTSum3Dataset(\n",
    "      data_dir,\n",
    "      train=True,\n",
    "      download=True,\n",
    "      transform=mnist_img_transform,\n",
    "    ),\n",
    "    collate_fn=MNISTSum3Dataset.collate_fn,\n",
    "    batch_size=batch_size_train,\n",
    "    shuffle=True\n",
    "  )\n",
    "\n",
    "  test_loader = torch.utils.data.DataLoader(\n",
    "    MNISTSum3Dataset(\n",
    "      data_dir,\n",
    "      train=False,\n",
    "      download=True,\n",
    "      transform=mnist_img_transform,\n",
    "    ),\n",
    "    collate_fn=MNISTSum3Dataset.collate_fn,\n",
    "    batch_size=batch_size_test,\n",
    "    shuffle=True\n",
    "  )\n",
    "\n",
    "  return train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can take a look into the dataset with matplotlib. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch, random\n",
    "\n",
    "# Feel free to modify the parameters below\n",
    "seed = 1234\n",
    "batch_size_train = 64\n",
    "batch_size_test = 64\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "data_dir = os.path.abspath(os.path.join(os.path.abspath(\"__file__\"), \"../data\"))\n",
    "train_loader, test_loader = mnist_sum_3_loader(data_dir, batch_size_train, batch_size_test)\n",
    "\n",
    "# Let's take a look into the dataset\n",
    "print(f\"The dataset size is: {len(train_loader)}.\")\n",
    "for (x, y) in train_loader:\n",
    "    # The dataloader will give you batches of three MNIST images and their sum \n",
    "    (a_imgs, b_imgs, c_imgs), digits = (x, y)\n",
    "    print(a_imgs.shape)\n",
    "\n",
    "    # We can peek the CLEVR image in the dataset\n",
    "    imgplot = plt.imshow(a_imgs[0].reshape(28, 28), cmap='gray')\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2** Construct a classifier `MNISTNet` that takes in an MNIST image and returns a tensor of the probability it is the number between 0~9. Here is a link to a tutorial: https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MNISTNet(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(MNISTNet, self).__init__()\n",
    "    # TODO:  Complete the __init__ function\n",
    "    raise NotImplementedError\n",
    "\n",
    "  def forward(self, x):\n",
    "    # TODO: Complete the forward function\n",
    "    raise NotImplementedError\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3** Construct a classifier `MNISTSum3Net` that takes in three MNIST images and returns a tensor of the distribution of their sum over 0 to 27."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scallopy\n",
    "class MNISTSum3Net(nn.Module):\n",
    "  def __init__(self, provenance, k):\n",
    "    super(MNISTSum3Net, self).__init__()\n",
    "    # TODO: Initialize the nueral network here. It should include:\n",
    "    #       1. MNISTNet\n",
    "    #       2. Scallop program\n",
    "    #       3. Forward function\n",
    "    raise NotImplementedError\n",
    "\n",
    "  def forward(self, x):\n",
    "    # TODO: Write the forward function for MNISTSum3Net\n",
    "    # Then execute the reasoning module; the expected return value is a size 28 tensor\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4** Setup trainer. We will use the BCE loss function for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "def bce_loss(output, ground_truth):\n",
    "  (_, dim) = output.shape\n",
    "  gt = torch.stack([torch.tensor([1.0 if i == t else 0.0 for i in range(dim)]) for t in ground_truth])\n",
    "  return F.binary_cross_entropy(output, gt)\n",
    "\n",
    "class Trainer():\n",
    "  def __init__(self, train_loader, test_loader, learning_rate, k, provenance):\n",
    "    self.network = MNISTSum3Net(provenance, k)\n",
    "    self.optimizer = optim.Adam(self.network.parameters(), lr=learning_rate)\n",
    "    self.train_loader = train_loader\n",
    "    self.test_loader = test_loader\n",
    "    self.loss = bce_loss\n",
    "\n",
    "  def train_epoch(self, epoch):\n",
    "    self.network.train()\n",
    "    iter = tqdm(self.train_loader, total=len(self.train_loader))\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data_ct, (data, target) in enumerate(iter):\n",
    "      self.optimizer.zero_grad()\n",
    "      output = self.network(data)\n",
    "\n",
    "      loss = self.loss(output, target)\n",
    "      loss.backward()\n",
    "      self.optimizer.step()\n",
    "      train_loss += loss.item()\n",
    "\n",
    "      pred = output.data.max(1, keepdim=True)[1]\n",
    "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "      total += pred.shape[0]\n",
    "      perc = 100. * correct / total\n",
    "      avg_loss = train_loss / (data_ct + 1)\n",
    "      iter.set_description(f\"[Train Epoch {epoch}] Total loss: {avg_loss:.4f}, Accuracy: {correct}/{total} ({perc:.2f}%)\")\n",
    "\n",
    "  def test(self, epoch):\n",
    "    self.network.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "      iter = tqdm(self.test_loader, total=len(self.test_loader))\n",
    "      for data_ct, (data, target) in enumerate(iter):\n",
    "        output = self.network(data)\n",
    "        test_loss += self.loss(output, target).item()\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "        total += pred.shape[0]\n",
    "        perc = 100. * correct / total\n",
    "        avg_loss = test_loss / (data_ct + 1)\n",
    "        iter.set_description(f\"[Test Epoch {epoch}] Total loss: {avg_loss:.4f}, Accuracy: {correct}/{total} ({perc:.2f}%)\")\n",
    "\n",
    "  def train(self, n_epochs):\n",
    "    self.test(0)\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "      self.train_epoch(epoch)\n",
    "      self.test(epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5** Train the model, and see the performance. :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to modify the parameters here\n",
    "n_epochs=3\n",
    "learning_rate=0.001\n",
    "provenance=\"difftopkproofs\"\n",
    "k=3\n",
    "\n",
    "trainer = Trainer(train_loader, test_loader, learning_rate, k, provenance)\n",
    "trainer.train(n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6** \n",
    "Let's plot the confusion matrix for the neural network, and check the performance for single-digit recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "diagnose_batch_size = 32\n",
    "mnist_diagnose_dataset = torchvision.datasets.MNIST(data_dir, train=False, download=True, transform=mnist_img_transform)\n",
    "mnist_loader = torch.utils.data.DataLoader(mnist_diagnose_dataset, batch_size=diagnose_batch_size)\n",
    "\n",
    "# Get prediction result\n",
    "y_true, y_pred = [], []\n",
    "with torch.no_grad():\n",
    "    for (imgs, digits) in mnist_loader:\n",
    "        pred_digits = numpy.argmax(trainer.network.mnist_net(imgs), axis=1)\n",
    "        y_true += [d.item() for (i, d) in enumerate(digits)]\n",
    "        y_pred += [d.item() for (i, d) in enumerate(pred_digits)]\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "df_cm = pd.DataFrame(cm, index=list(range(10)), columns=list(range(10)))\n",
    "plt.figure(figsize=(10,7))\n",
    "sn.heatmap(df_cm, annot=True, cmap=plt.cm.Blues)\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P4. MNIST Sort 2\n",
    "In this practice, we will learn the MNIST digit recognition through the sort 2 task. The task takes in two MNIST digits and returns 0 if the first digit is smaller than the second image, otherwise, returns 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1** Dataloader construction. \n",
    "\n",
    "First, we want to construct a train data loader, and a test data loader separately. \n",
    "The `get_item` function shall take in an index and return a tuple. The first tuple element is a tuple of tensorized images, and the second tuple element is 0 or 1.\n",
    "The `collate_fn` function shall take in a list of tuples returned by `get_item`, and return a tuple. The first tuple element is tuples of batched tensors representing the images, and the second element is a tensor of batched 0 or 1s. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Implent the MNISTSort2Dataset and the Dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2** Construct a classifier `MNISTSort2Net` that takes in two MNIST images and returns a tensor of the distribution over 0 and 1. You can utilize the previously defined class `MNISTNet`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Implement the MNISTSort2Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3** Setup trainer and loss function. We will use the BCE loss function for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement the loss function and Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4** Train the model with different extended provenance semirings and check the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Perform model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5** \n",
    "Please plot the confusion matrix for the neural network with different extended provenance semiring setups.\n",
    "1. diffminmaxprob\n",
    "2. difftopkproofs with k = 3\n",
    "3. difftopkproofs with k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Perform error analysis using confusion matrix \n",
    "# using the three extended provenance semirings mentioned above."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1879f963aa2f8d328388bc1cf13624c775488f3439145d75b1b99880fdb1524c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('scallop-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
