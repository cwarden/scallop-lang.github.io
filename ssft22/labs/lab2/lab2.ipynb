{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In lab2, we will guide you through the basic Scallop Python API, called `scallopy`.\n",
    "In this tutorial, you will learn:\n",
    "1. How to construct and execute a Scallop program in Python using `scallopy`.\n",
    "2. How to perform a learning task in Python through `scallopy`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hello Scallopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write our first hello world Python program. You can do this purely through the scallopy interface. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start from constructing a scallopy context\n",
    "import scallopy\n",
    "ctx = scallopy.ScallopContext()\n",
    "\n",
    "# We declare a relation type using 'add_relation'. \n",
    "# This is equvalent to 'type hello(String)' in a .scl file\n",
    "ctx.add_relation(\"hello\", str)\n",
    "\n",
    "# We add the fact hello(\"Hello World\") to the scallopy context \n",
    "ctx.add_facts(\"hello\", [(\"Hello World\",)])\n",
    "\n",
    "# We can execute the context through 'run'\n",
    "ctx.run()\n",
    "print(list(ctx.relation(\"hello\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## MNIST\n",
    "\n",
    "![img/mnist_example.png](https://github.com/scallop-lang/scallop-lang.github.io/blob/master/img/summer_school/lab2/mnist_example.png?raw=true)\n",
    "\n",
    "### P1: Count How Many 2\n",
    "\n",
    "Let's first construct the symbolic representation of the MNIST images shown above.\n",
    "You should use the function `ctx.add_relation(RELATION_NAME, TUPLE_OF_TYPES)` to declare the type of relations,\n",
    "and use the function `ctx.add_facts(RELATION_NAME, TUPLES)` to add a list of tuples into the relation `RELATION_NAME`.\n",
    "For `TUPLE_OF_TYPES`, you can use `(int, int)` to represent a tuple of two integers, where `int` is idiomatic Python type annotation.\n",
    "The expected input facts for `digit(i, d)` should represent the mapping from image ID `i` to its numerical digit `d`.\n",
    "Note that in order for any fact to be added to the context, you have to declare the type of that relation beforehands.\n",
    "\n",
    "Then, please use the function `ctx.add_rule(RULE_STRING)` to add a rule that counts how many `2` are there in the image.\n",
    "This rule should start with `\"num_of_2(n) = FILL_IN_YOUR_RULE_BODY\"`.\n",
    "Note that we have omitted the `rel` keyword before the rule, \n",
    "and you don't need to declare the type of the relation `num_of_2` beforehand since `scallopy` can infer the type from the rule.\n",
    "\n",
    "At the end, you should be able to see `[(1,)]` being printed out:\n",
    "The relation `num_of_2` is a set of unary tuples and there is only one tuple containing the count of 2.\n",
    "The tuple contains `1` suggesting that there is only one `2` among the digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scallopy\n",
    "\n",
    "ctx = scallopy.ScallopContext()\n",
    "\n",
    "# TODO: 1. Declare the relation `digit`\n",
    "# TODO: 2. Add facts into the relation `digit`\n",
    "# TODO: 3. Add a rule that counts the number of `2`s from the given digits. Populate a relation `num_of_2`\n",
    "\n",
    "ctx.run()\n",
    "print(list(ctx.relation(\"num_of_2\"))) # Should be printing [(1,)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P2: Count How Many Less Than 5, Probabilistic\n",
    "\n",
    "Let's try to write a probabilistic symbolic representation of the MNIST images.\n",
    "Similar to the previous problem, please add the relation and facts for the relation `digit`.\n",
    "However, when adding the facts this time, let's do it with probabilities!\n",
    "\n",
    "``` python\n",
    "ctx.add_fact(RELATION_NAME, [(PROB, TUPLE), (PROB, TUPLE), ...])\n",
    "```\n",
    "\n",
    "Now, since we have the full Python syntax at hand, you are free to use `random()` to generate `[0, 1]` floating point numbers,\n",
    "for loop and even list comprehensions.\n",
    "If you choose to randomly generate probabilities, make sure you have the probability distribution for each digit sum up to 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from random import random\n",
    "import scallopy\n",
    "\n",
    "provenance = \"FILL_IN_YOUR_PROVENANCE\"\n",
    "provenance = \"minmaxprob\"\n",
    "ctx = scallopy.ScallopContext(provenance=provenance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P3: MNIST Sum 2\n",
    "\n",
    "The whole purpose of this experiment is for you to see through the MNIST Sum 2 Experiment!\n",
    "We are showing all the code needed to actually run the experiment, separated into chunks.\n",
    "There are parts you don't need to pay much attention and parts that you want to understand a few functions.\n",
    "\n",
    "The block below just imports dependencies and setup some pre-requisites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from typing import *\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "mnist_img_transform = torchvision.transforms.Compose([\n",
    "  torchvision.transforms.ToTensor(),\n",
    "  torchvision.transforms.Normalize(\n",
    "    (0.1307,), (0.3081,)\n",
    "  )\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MNIST Sum 2 Dataset\n",
    "\n",
    "The following class `MNISTSum2Dataset` defines a dataset.\n",
    "A PyTorch dataset needs to implement two functions, `__len__()` (length) and `__getitem__(index: int)`.\n",
    "\n",
    "In our case, we base our dataset on the original MNIST dataset provided by `torchvision`.\n",
    "We randomize the source dataset by creating a suffled index map.\n",
    "And since the resulting input will be two images, we will pull two data-points from the MNIST dataset.\n",
    "At the end, each data-point will have three things: the two input images and the sum of the two digits (integer).\n",
    "\n",
    "There is also a `collate_fn` that collate data-points into batches.\n",
    "The input `batch` is a list of tuples `(a_img, b_img, a_digit + b_digit)`.\n",
    "It will return tuple of three batches of elements: `((a_imgs, b_imgs), digits)`.\n",
    "Note that there are only two elements in this tuple since we want each data-point to be separated into input `x` and ground-truth `y`.\n",
    "Inside of it, we use `torch.stack(LIST_OF_TENSORS)` to \"stack\" images into batch of images.\n",
    "At the end, `a_imgs` and `b_imgs` will be two batches of 64 images (64 is the \"batch size\" as we call it),\n",
    "and `digits` will be a batch of 64 numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTSum2Dataset(torch.utils.data.Dataset):\n",
    "  def __init__(self, root: str, train: bool = True, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False):\n",
    "    # Contains a MNIST dataset\n",
    "    self.mnist_dataset = torchvision.datasets.MNIST(root, train=train, transform=transform, target_transform=target_transform, download=download)\n",
    "    self.index_map = list(range(len(self.mnist_dataset)))\n",
    "    random.shuffle(self.index_map)\n",
    "\n",
    "  def __len__(self):\n",
    "    return int(len(self.mnist_dataset) / 2)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    # Get two data points\n",
    "    (a_img, a_digit) = self.mnist_dataset[self.index_map[idx * 2]]\n",
    "    (b_img, b_digit) = self.mnist_dataset[self.index_map[idx * 2 + 1]]\n",
    "\n",
    "    # Each data has two images and the GT is the sum of two digits\n",
    "    return (a_img, b_img, a_digit + b_digit)\n",
    "\n",
    "  @staticmethod\n",
    "  def collate_fn(batch):\n",
    "    a_imgs = torch.stack([item[0] for item in batch])\n",
    "    b_imgs = torch.stack([item[1] for item in batch])\n",
    "    digits = torch.stack([torch.tensor(item[2]).long() for item in batch])\n",
    "    return ((a_imgs, b_imgs), digits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Dataloader for MNIST Sum 2\n",
    "\n",
    "This is a wrapper outside of the `MNISTSum2Dataset` so that it produces shuffled and batched input and output pairs.\n",
    "Not too interesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_sum_2_loader(data_dir, batch_size_train, batch_size_test):\n",
    "  train_loader = torch.utils.data.DataLoader(\n",
    "    MNISTSum2Dataset(data_dir, train=True, download=True, transform=mnist_img_transform),\n",
    "    collate_fn=MNISTSum2Dataset.collate_fn,\n",
    "    batch_size=batch_size_train,\n",
    "    shuffle=True\n",
    "  )\n",
    "  test_loader = torch.utils.data.DataLoader(\n",
    "    MNISTSum2Dataset(data_dir, train=False, download=True, transform=mnist_img_transform),\n",
    "    collate_fn=MNISTSum2Dataset.collate_fn,\n",
    "    batch_size=batch_size_test,\n",
    "    shuffle=True\n",
    "  )\n",
    "  return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MNIST Neural Network\n",
    "\n",
    "This is the MNIST Neural Network based on Convolutional Neural Networks (CNN).\n",
    "Inside of initialization, we have two convolutional layers and two linear layers.\n",
    "During forward, we take in the input `x` (which should be a batch of images) and output a tensor of size 64 x 10 (notice that `self.fc2`, the last layer of the network, has an output size of 10).\n",
    "At the end, we will do a `softmax` step to create a probabilistic distribution of 10 possibilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTNet(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(MNISTNet, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "    self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
    "    self.fc1 = nn.Linear(1024, 1024)\n",
    "    self.fc2 = nn.Linear(1024, 10)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = F.max_pool2d(self.conv1(x), 2)\n",
    "    x = F.max_pool2d(self.conv2(x), 2)\n",
    "    x = x.view(-1, 1024)\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = F.dropout(x, p = 0.5, training=self.training)\n",
    "    x = self.fc2(x)\n",
    "    return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MNIST Sum 2 Model\n",
    "\n",
    "This model combines the perception model (MNISTNet) and Sum 2 Scallop Program.\n",
    "During initialization, we setup our `MNISTNet` for training.\n",
    "Additionally, we setup the `ScallopContext`, which is a member of `scallopy`.\n",
    "Note that the `provenance` is customizable and stated as an input to the `MNISTSum2Net`.\n",
    "We add the relations `digit_1` and `digit_2`, and setup the `input_mapping`s, and add the rule of the `sum_2` relation.\n",
    "Finally, we setup a forward function that takes the relation `sum_2` out and apply an `output_mapping` to turn it into a PyTorch tensor.\n",
    "\n",
    "During `forward`, we apply `self.mnist_net` on both batches of images, and pass these into the `sum_2` forward function.\n",
    "Note that there are named parameters so that `a_distrs` is passed into `\"digit_1\"` relation and `b_distrs` is passed into the `\"digit_2\"` relation.\n",
    "At the end, this function will return a Batch Size x 19 tensor, since we have setup an `output_mapping` of size 19."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTSum2Net(nn.Module):\n",
    "  def __init__(self, provenance, k):\n",
    "    super(MNISTSum2Net, self).__init__()\n",
    "\n",
    "    # MNIST Digit Recognition Network\n",
    "    self.mnist_net = MNISTNet()\n",
    "\n",
    "    # Scallop Context\n",
    "    self.scl_ctx = scallopy.ScallopContext(provenance=provenance, k=k)\n",
    "    self.scl_ctx.add_relation(\"digit_1\", int, input_mapping=list(range(10)))\n",
    "    self.scl_ctx.add_relation(\"digit_2\", int, input_mapping=list(range(10)))\n",
    "    self.scl_ctx.add_rule(\"sum_2(a + b) :- digit_1(a), digit_2(b)\")\n",
    "\n",
    "    # The `sum_2` logical reasoning module\n",
    "    self.sum_2 = self.scl_ctx.forward_function(\"sum_2\", output_mapping=[(i,) for i in range(19)])\n",
    "\n",
    "  def forward(self, x: Tuple[torch.Tensor, torch.Tensor]):\n",
    "    (a_imgs, b_imgs) = x\n",
    "\n",
    "    # First recognize the two digits\n",
    "    a_distrs = self.mnist_net(a_imgs) # Tensor 64 x 10\n",
    "    b_distrs = self.mnist_net(b_imgs) # Tensor 64 x 10\n",
    "\n",
    "    # Then execute the reasoning module; the result is a size 19 tensor\n",
    "    return self.sum_2(digit_1=a_distrs, digit_2=b_distrs) # Tensor 64 x 19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MNIST Sum 2 Trainer\n",
    "\n",
    "This `MNISTSum2Trainer` class takes care of the training loop.\n",
    "During initialization, we setup our `MNISTSum2Net` and setup our optimizer and two data loaders (for training and testing).\n",
    "For a training epoch, we will pass the input `x` into the network and which will produce the output `y_pred`.\n",
    "`y_pred` will be compared with `y` in a BCE loss function and the loss will be back-propagated into the neural networks.\n",
    "\n",
    "We will start by running a `test_epoch` just to understand what the accuracy with no training is.\n",
    "After that, we will alternate between `train_epoch` and `test_epoch` to see what improvement we have obtained for each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTSum2Trainer:\n",
    "  def __init__(self, train_loader, test_loader, learning_rate, k, provenance):\n",
    "    self.network = MNISTSum2Net(provenance, k)\n",
    "    self.optimizer = optim.Adam(self.network.parameters(), lr=learning_rate)\n",
    "    self.train_loader = train_loader\n",
    "    self.test_loader = test_loader\n",
    "\n",
    "  def bce_loss(self, y_pred, y):\n",
    "    (_, dim) = y_pred.shape\n",
    "    gt = torch.stack([torch.tensor([1.0 if i == t else 0.0 for i in range(dim)]) for t in y])\n",
    "    return F.binary_cross_entropy(y_pred, gt)\n",
    "  \n",
    "  def train_epoch(self, epoch):\n",
    "    self.network.train()\n",
    "    iter = tqdm(self.train_loader, total=len(self.train_loader))\n",
    "    for (x, y) in iter:\n",
    "      self.optimizer.zero_grad()\n",
    "      y_pred = self.network(x)\n",
    "      loss = self.bce_loss(y_pred, y)\n",
    "      loss.backward()\n",
    "      self.optimizer.step()\n",
    "      iter.set_description(f\"[Train Epoch {epoch}] Loss: {loss.item():.4f}\")\n",
    "\n",
    "  def test_epoch(self, epoch):\n",
    "    self.network.eval()\n",
    "    num_items = len(self.test_loader.dataset)\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "      iter = tqdm(self.test_loader, total=len(self.test_loader))\n",
    "      for (x, y) in iter:\n",
    "        output = self.network(x)\n",
    "        test_loss += self.bce_loss(output, y).item()\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(y.data.view_as(pred)).sum()\n",
    "        perc = 100. * correct / num_items\n",
    "        iter.set_description(f\"[Test Epoch {epoch}] Total loss: {test_loss:.4f}, Accuracy: {correct}/{num_items} ({perc:.2f}%)\")\n",
    "\n",
    "  def train(self, n_epochs):\n",
    "    self.test_epoch(0)\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "      self.train_epoch(epoch)\n",
    "      self.test_epoch(epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, try to run the following block, while tuning the parameters among\n",
    "- `difftopkproofs`\n",
    "- `diffminmaxprob`\n",
    "- `diffaddmultprob`\n",
    "\n",
    "And for `difftopkproofs`, please also tune the value of `k` and record the numbers in the following table:\n",
    "\n",
    "| Iteration | difftop1proofs | difftop3proofs | difftop10proofs | diffminmaxprob | diffaddmultprob |\n",
    "|-----------|----------------|----------------|-----------------|----------------|-----------------|\n",
    "| Epoch 1   | ??% | ??% | ??% | ??% | ??% |\n",
    "| Epoch 2   | ??% | ??% | ??% | ??% | ??% |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mnist_sum_2():\n",
    "  data_dir = \".\"\n",
    "  batch_size_train = 64\n",
    "  batch_size_test = 64\n",
    "  n_epochs = 2\n",
    "  learning_rate = 0.001\n",
    "  provenance = \"difftopkproofs\"\n",
    "  k = 3\n",
    "\n",
    "  train_loader, test_loader = mnist_sum_2_loader(data_dir, batch_size_train, batch_size_test)\n",
    "  trainer = MNISTSum2Trainer(train_loader, test_loader, learning_rate, k, provenance)\n",
    "  trainer.train(n_epochs)\n",
    "\n",
    "run_mnist_sum_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P4: MNIST Sum 3\n",
    "In this practice, we will use scallopy to train an MNIST digit recognition network. Given three MNIST numbers and their sum, we want to train a classifier that can identify the digits, and yields a correct sum of the input images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1** Dataloader construction. \n",
    "\n",
    "First, we want to construct a train data loader, and a test data loader separately. \n",
    "Please fill in the `get_item` and `collate_fn` functions for the dataloader.\n",
    "The `get_item` function shall take in an index and return a tuple. The first tuple element is a triplet of tensorized images, and the second tuple element is the sum of the images.\n",
    "The `collate_fn` function shall take in a list of tuples returned by `get_item`, and return a tuple. The first tuple element is a triplet of batched tensors representing the images, and the second element is a tensor of batched sum values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTSum3Dataset(torch.utils.data.Dataset):\n",
    "  def __init__(\n",
    "    self,\n",
    "    root: str,\n",
    "    train: bool = True,\n",
    "    transform: Optional[Callable] = None,\n",
    "    target_transform: Optional[Callable] = None,\n",
    "    download: bool = False,\n",
    "  ):\n",
    "    # Contains a MNIST dataset\n",
    "    self.mnist_dataset = torchvision.datasets.MNIST(\n",
    "      root,\n",
    "      train=train,\n",
    "      transform=transform,\n",
    "      target_transform=target_transform,\n",
    "      download=download,\n",
    "    )\n",
    "    self.index_map = list(range(len(self.mnist_dataset)))\n",
    "    random.shuffle(self.index_map)\n",
    "\n",
    "  def __len__(self):\n",
    "    return int(len(self.mnist_dataset) / 3)\n",
    "\n",
    "  # The `get_item` function shall take in an index and return a tuple. \n",
    "  # The first tuple element is a triplet of tensorized images, \n",
    "  # and the second tuple element is the sum of the images.\n",
    "  def __getitem__(self, idx):\n",
    "    # TODO: Complete the __getitem__ method\n",
    "    raise NotImplementedError\n",
    "\n",
    "  # The `collate_fn` function shall take in a list of tuples returned by `get_item`, \n",
    "  # and return a tuple. The first tuple element is triplet of batched tensors \n",
    "  # representing the images, and the second element is a tensor of batched sum values.  \n",
    "  @staticmethod\n",
    "  def collate_fn(batch):\n",
    "    # TODO: complete the collate_fn method\n",
    "    raise NotImplementedError\n",
    "\n",
    "def mnist_sum_3_loader(data_dir, batch_size_train, batch_size_test):\n",
    "\n",
    "  train_loader = torch.utils.data.DataLoader(\n",
    "    MNISTSum3Dataset(\n",
    "      data_dir,\n",
    "      train=True,\n",
    "      download=True,\n",
    "      transform=mnist_img_transform,\n",
    "    ),\n",
    "    collate_fn=MNISTSum3Dataset.collate_fn,\n",
    "    batch_size=batch_size_train,\n",
    "    shuffle=True\n",
    "  )\n",
    "\n",
    "  test_loader = torch.utils.data.DataLoader(\n",
    "    MNISTSum3Dataset(\n",
    "      data_dir,\n",
    "      train=False,\n",
    "      download=True,\n",
    "      transform=mnist_img_transform,\n",
    "    ),\n",
    "    collate_fn=MNISTSum3Dataset.collate_fn,\n",
    "    batch_size=batch_size_test,\n",
    "    shuffle=True\n",
    "  )\n",
    "\n",
    "  return train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can take a look into the dataset with matplotlib. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch, random\n",
    "\n",
    "# Feel free to modify the parameters below\n",
    "seed = 1234\n",
    "batch_size_train = 64\n",
    "batch_size_test = 64\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "data_dir = os.path.abspath(os.path.join(os.path.abspath(\"__file__\"), \"../data\"))\n",
    "train_loader, test_loader = mnist_sum_3_loader(data_dir, batch_size_train, batch_size_test)\n",
    "\n",
    "# Let's take a look into the dataset\n",
    "print(f\"The dataset size is: {len(train_loader)}.\")\n",
    "for (x, y) in train_loader:\n",
    "    # The dataloader will give you batches of three MNIST images and their sum \n",
    "    (a_imgs, b_imgs, c_imgs), digits = (x, y)\n",
    "    print(a_imgs.shape)\n",
    "\n",
    "    # We can peek the CLEVR image in the dataset\n",
    "    imgplot = plt.imshow(a_imgs[0].reshape(28, 28), cmap='gray')\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2** Construct a classifier `MNISTSum3Net` that takes in three MNIST images and returns a tensor of the distribution of their sum over 0 to 27."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scallopy\n",
    "class MNISTSum3Net(nn.Module):\n",
    "  def __init__(self, provenance, k):\n",
    "    super(MNISTSum3Net, self).__init__()\n",
    "    # TODO: Initialize the nueral network here. It should include:\n",
    "    #       1. MNISTNet\n",
    "    #       2. Scallop program\n",
    "    #       3. Forward function\n",
    "    raise NotImplementedError\n",
    "\n",
    "  def forward(self, x):\n",
    "    # TODO: Write the forward function for MNISTSum3Net\n",
    "    # Then execute the reasoning module; the expected return value is a size 28 tensor\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3** Setup trainer. We will use the BCE loss function for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "def bce_loss(output, ground_truth):\n",
    "  (_, dim) = output.shape\n",
    "  gt = torch.stack([torch.tensor([1.0 if i == t else 0.0 for i in range(dim)]) for t in ground_truth])\n",
    "  return F.binary_cross_entropy(output, gt)\n",
    "\n",
    "class Trainer():\n",
    "  def __init__(self, train_loader, test_loader, learning_rate, k, provenance):\n",
    "    self.network = MNISTSum3Net(provenance, k)\n",
    "    self.optimizer = optim.Adam(self.network.parameters(), lr=learning_rate)\n",
    "    self.train_loader = train_loader\n",
    "    self.test_loader = test_loader\n",
    "    self.loss = bce_loss\n",
    "\n",
    "  def train_epoch(self, epoch):\n",
    "    self.network.train()\n",
    "    iter = tqdm(self.train_loader, total=len(self.train_loader))\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data_ct, (data, target) in enumerate(iter):\n",
    "      self.optimizer.zero_grad()\n",
    "      output = self.network(data)\n",
    "\n",
    "      loss = self.loss(output, target)\n",
    "      loss.backward()\n",
    "      self.optimizer.step()\n",
    "      train_loss += loss.item()\n",
    "\n",
    "      pred = output.data.max(1, keepdim=True)[1]\n",
    "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "      total += pred.shape[0]\n",
    "      perc = 100. * correct / total\n",
    "      avg_loss = train_loss / (data_ct + 1)\n",
    "      iter.set_description(f\"[Train Epoch {epoch}] Total loss: {avg_loss:.4f}, Accuracy: {correct}/{total} ({perc:.2f}%)\")\n",
    "\n",
    "  def test(self, epoch):\n",
    "    self.network.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "      iter = tqdm(self.test_loader, total=len(self.test_loader))\n",
    "      for data_ct, (data, target) in enumerate(iter):\n",
    "        output = self.network(data)\n",
    "        test_loss += self.loss(output, target).item()\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "        total += pred.shape[0]\n",
    "        perc = 100. * correct / total\n",
    "        avg_loss = test_loss / (data_ct + 1)\n",
    "        iter.set_description(f\"[Test Epoch {epoch}] Total loss: {avg_loss:.4f}, Accuracy: {correct}/{total} ({perc:.2f}%)\")\n",
    "\n",
    "  def train(self, n_epochs):\n",
    "    self.test(0)\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "      self.train_epoch(epoch)\n",
    "      self.test(epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4** Train the model, and see the performance. :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sum_3():\n",
    "  # Feel free to modify the parameters here\n",
    "  n_epochs=3\n",
    "  learning_rate=0.001\n",
    "  provenance=\"difftopkproofs\"\n",
    "  k=3\n",
    "\n",
    "  trainer = Trainer(train_loader, test_loader, learning_rate, k, provenance)\n",
    "  trainer.train(n_epochs)\n",
    "\n",
    "train_sum_3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5** \n",
    "Let's plot the confusion matrix for the neural network, and check the performance for single-digit recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "diagnose_batch_size = 32\n",
    "mnist_diagnose_dataset = torchvision.datasets.MNIST(data_dir, train=False, download=True, transform=mnist_img_transform)\n",
    "mnist_loader = torch.utils.data.DataLoader(mnist_diagnose_dataset, batch_size=diagnose_batch_size)\n",
    "\n",
    "# Get prediction result\n",
    "y_true, y_pred = [], []\n",
    "with torch.no_grad():\n",
    "    for (imgs, digits) in mnist_loader:\n",
    "        pred_digits = numpy.argmax(trainer.network.mnist_net(imgs), axis=1)\n",
    "        y_true += [d.item() for (i, d) in enumerate(digits)]\n",
    "        y_pred += [d.item() for (i, d) in enumerate(pred_digits)]\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "df_cm = pd.DataFrame(cm, index=list(range(10)), columns=list(range(10)))\n",
    "plt.figure(figsize=(10,7))\n",
    "sn.heatmap(df_cm, annot=True, cmap=plt.cm.Blues)\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P5: MNIST Sort 2\n",
    "In this practice, we will learn the MNIST digit recognition through the sort 2 task. The task takes in two MNIST digits and returns 0 if the first digit is smaller than the second image, otherwise, returns 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1** Dataloader construction. \n",
    "\n",
    "First, we want to construct a train data loader, and a test data loader separately. \n",
    "The `get_item` function shall take in an index and return a tuple. The first tuple element is a tuple of tensorized images, and the second tuple element is 0 or 1.\n",
    "The `collate_fn` function shall take in a list of tuples returned by `get_item`, and return a tuple. The first tuple element is tuples of batched tensors representing the images, and the second element is a tensor of batched 0 or 1s. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Implent the MNISTSort2Dataset and the Dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2** Construct a classifier `MNISTSort2Net` that takes in two MNIST images and returns a tensor of the distribution over 0 and 1. You can utilize the previously defined class `MNISTNet`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Implement the MNISTSort2Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3** Setup trainer and loss function. We will use the BCE loss function for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement the loss function and Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4** Train the model with different extended provenance semirings and check the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Perform model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5** \n",
    "Please plot the confusion matrix for the neural network with different extended provenance semiring setups.\n",
    "1. diffminmaxprob\n",
    "2. difftopkproofs with k = 3\n",
    "3. difftopkproofs with k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Perform error analysis using confusion matrix \n",
    "# using the three extended provenance semirings mentioned above."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cd7d644057bc244b01cbb3a48b2975ab1785b1e9d5569fa703624f2f0391f5c2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('scallop-dev-cp39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
