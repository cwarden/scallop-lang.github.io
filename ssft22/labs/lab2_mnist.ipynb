{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In lab2, we will guide you through the basic Scallop Python API, called scallopy.\n",
    "In this tutorial, you will learn:\n",
    "1. How to construct and execute a Scallop program in Python using Scallopy.\n",
    "2. How to import a .scl file into Python, and how to interact with the .scl file with Scallopy.\n",
    "3. How to perform a learning task in python with Scallop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hello Scallopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write our first hello world Python program. You can do this purely through the scallopy interface. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start from constructing a scallopy context\n",
    "import scallopy\n",
    "ctx = scallopy.ScallopContext()\n",
    "\n",
    "# We declare a relation type using 'add_relation'. \n",
    "# This is equvalent to 'type hello(String)' in a .scl file\n",
    "ctx.add_relation(\"hello\", str)\n",
    "\n",
    "# We add the fact hello(\"Hello World\") to the scallopy context \n",
    "ctx.add_facts(\"hello\", [(\"Hello World\",)])\n",
    "\n",
    "# We can execute the context through 'run'\n",
    "ctx.run()\n",
    "print(list(ctx.relation(\"hello\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also import an scl file to the scallopy context, as shown in the example below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define a helper fucntion here to inspect what does the scl file look like\n",
    "def print_scl_file(scl_path):\n",
    "    print(\"---------- scl file -----------\")\n",
    "    !cat $scl_path\n",
    "    print(\"-------------------------------\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup scl file directory\n",
    "import os\n",
    "import scallopy\n",
    "\n",
    "scl_dir = os.path.abspath(os.path.join(os.path.abspath(\"__file__\"), \"../scl\"))\n",
    "scl_path = os.path.join(scl_dir, \"hello_world.scl\")\n",
    "print_scl_file(scl_path)\n",
    "\n",
    "ctx = scallopy.ScallopContext()\n",
    "\n",
    "# Import and run the scl file\n",
    "ctx.import_file(scl_path)\n",
    "ctx.run()\n",
    "print(list(ctx.relation('hello')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Learning with .scl\n",
    "Because the type definition is pretty unnatural to directly perform in Python, the common practice is to put the type definition and relations into an .scl file; while we can use scallopy to add the probabilistic facts to be learnt online during the learning process.\n",
    "We can thus enjoy the following benefits:\n",
    " - better efficiency\n",
    " - better error message\n",
    " - better type compatibility\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## MNIST\n",
    "<div>\n",
    "  <img src=\"img/mnist_example.png\" width=\"300\"/>\n",
    "</div>\n",
    "\n",
    "### P1. Count 2\n",
    "- In this jupyter notebook:\n",
    "The first practice is to write a relation `digit(i, d)` where i is the image id, and d is the numerical value of the corresponding image using scallopy.\n",
    "- In scl file:\n",
    "Write a rule count the number of 2 existing in the image in `scl/mnist_count_2.scl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scallopy\n",
    "\n",
    "scl_dir = os.path.abspath(os.path.join(os.path.abspath(\"__file__\"), \"../scl\"))\n",
    "scl_path = os.path.join(scl_dir, \"mnist_count_2.scl\")\n",
    "print_scl_file(scl_path)\n",
    "\n",
    "# We import the type definition and relations from the scl file \n",
    "ctx = scallopy.ScallopContext()\n",
    "ctx.import_file(scl_path)\n",
    "\n",
    "# We add the scene graph of the image into the context as facts in python\n",
    "ctx.add_facts(\"object_color\", [(0, \"red\"), (1, \"green\"), (2, \"green\")])\n",
    "\n",
    "ctx.run()\n",
    "print(list(ctx.relation(\"green_obj\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning in Scallop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MNIST Sum 3\n",
    "Given three mnist images and their sum, can we learn what are the three digits seperatly? \n",
    "<div>\n",
    "  <img src=\"img/mnist_example.png\" width=\"300\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1** Get familiar with the MNIST sum 3 dataloader.\n",
    "We have prepared two dataloaders for you, one is for training and the other is for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MNIST_sum_3_dataloader import mnist_sum_3_loader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch, random\n",
    "\n",
    "# Ensure we have duplicatable result during implementation + debug\n",
    "seed = 1234\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# Set batch size here\n",
    "batch_size_train = 8\n",
    "batch_size_test = 8\n",
    "train_loader, test_loader = mnist_sum_3_loader(batch_size_train, batch_size_test)\n",
    "\n",
    "# Let's take a look into the dataset\n",
    "print(f\"The dataset size is: {len(train_loader)}.\")\n",
    "for (x, y) in train_loader:\n",
    "    # The dataloader will give you batches of three MNIST images and their sum \n",
    "    (a_imgs, b_imgs, c_imgs), digits = (x, y)\n",
    "    print(a_imgs.shape)\n",
    "\n",
    "    # We can peek the CLEVR image in the dataset\n",
    "    imgplot = plt.imshow(a_imgs[0].reshape(28, 28), cmap='gray')\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2** Construct a classifier `MNISTNet` that takes in an MNIST image, and return a tensor of the probability it is the number between 0~9. Here is a link to a tutorial: https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MNISTNet(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(MNISTNet, self).__init__()\n",
    "    # TODO\n",
    "    pass\n",
    "\n",
    "  def forward(self, x):\n",
    "    # TODO\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3** Construct a classifier `MNISTSum3Net` that takes in three MNIST images, and return a tensor of the distribution of their sum over 0 to 27."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scallopy\n",
    "class MNISTSum3Net(nn.Module):\n",
    "  def __init__(self, provenance, k):\n",
    "    super(MNISTSum3Net, self).__init__()\n",
    "    # TODO: Initialize the nueral network here. It should include:\n",
    "    #       1. MNISTNet\n",
    "    #       2. Scallop program\n",
    "    #       3. Forward function\n",
    "    pass\n",
    "\n",
    "  def forward(self, x):\n",
    "    # TODO: Write the forward function for MNISTSum3Net\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4** Setup trainer and loss function. We will use the BCE loss function for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "def bce_loss(output, ground_truth):\n",
    "  (_, dim) = output.shape\n",
    "  gt = torch.stack([torch.tensor([1.0 if i == t else 0.0 for i in range(dim)]) for t in ground_truth])\n",
    "  return F.binary_cross_entropy(output, gt)\n",
    "\n",
    "class Trainer():\n",
    "  def __init__(self, train_loader, test_loader, learning_rate, k, provenance):\n",
    "    self.network = MNISTSum3Net(provenance, k)\n",
    "    self.optimizer = optim.Adam(self.network.parameters(), lr=learning_rate)\n",
    "    self.train_loader = train_loader\n",
    "    self.test_loader = test_loader\n",
    "    self.loss = bce_loss\n",
    "\n",
    "  def train_epoch(self, epoch):\n",
    "    self.network.train()\n",
    "    iter = tqdm(self.train_loader, total=len(self.train_loader))\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    for data_ct, (data, target) in enumerate(iter):\n",
    "      self.optimizer.zero_grad()\n",
    "      output = self.network(data)\n",
    "\n",
    "      loss = self.loss(output, target)\n",
    "      loss.backward()\n",
    "      self.optimizer.step()\n",
    "      train_loss += loss.item()\n",
    "\n",
    "      pred = output.data.max(1, keepdim=True)[1]\n",
    "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "      perc = 100. * correct / ((data_ct + 1) * pred.shape[0])\n",
    "      avg_loss = train_loss / (data_ct + 1)\n",
    "      iter.set_description(f\"[Train Epoch {epoch}] Total loss: {avg_loss:.4f}, Accuracy: {correct}/{(data_ct + 1) * pred.shape[0]} ({perc:.2f}%)\")\n",
    "\n",
    "  def test(self, epoch):\n",
    "    self.network.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "      iter = tqdm(self.test_loader, total=len(self.test_loader))\n",
    "      for data_ct, (data, target) in enumerate(iter):\n",
    "        output = self.network(data)\n",
    "        test_loss += self.loss(output, target).item()\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "        perc = 100. * correct / ((data_ct + 1) * pred.shape[0])\n",
    "        avg_loss = test_loss / (data_ct + 1)\n",
    "        iter.set_description(f\"[Test Epoch {epoch}] Total loss: {avg_loss:.4f}, Accuracy: {correct}/{(data_ct + 1) * pred.shape[0]} ({perc:.2f}%)\")\n",
    "\n",
    "  def train(self, n_epochs):\n",
    "    self.test(0)\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "      self.train_epoch(epoch)\n",
    "      self.test(epoch)\n",
    "      break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5** Train the model, and see the performance. :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=10\n",
    "learning_rate=0.001\n",
    "provenance=\"difftopkproofs\"\n",
    "k=3\n",
    "\n",
    "trainer = Trainer(train_loader, test_loader, learning_rate, k, provenance)\n",
    "trainer.train(n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLEVR - color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1879f963aa2f8d328388bc1cf13624c775488f3439145d75b1b99880fdb1524c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('scallop-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
